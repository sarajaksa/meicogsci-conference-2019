... title: Listening to the multimodal orchestra of the senses:  Vision inductively infers about real-world objects from haptic information



Abstract

During binocular rivalry each eye is presented different visual stimuli, resulting in a perceptual conflict situation. For instance, when an horizontal grid is presented to the one eye while the other eye sees a vertical grid, consciousness will select stochastically either the one object or the other. As time passes, the exclusive dominance will be challenged so that the other object gets selected, leading to alternating dynamics of perceptual switches. This phenomenon has been used to study a multitude of psychophysical questions and to reveal the dynamics of visual cognition and the neural mechanisms of perception [1]. 
In cognitive science, recent development towards an embodied cognition view stresses a more action- and context-dependent perspective on the organization of perception. The notion here is that perception is primarly a process for the coordination of an organism‘s activity in the environment, which lead to the concept of perception-action-cycle. This approach is not only significant for biology, neuroscience and cognitive psychology, but also for the field of robotics and human-machine-interaction. Activities of primates, like grasping, jumping or exploring are well coordinated sensorimotor patterns consisting of perceptual coincidences from different sensory modalities which are taken to further compute proper actions. Thus, a well concerted, and bidirectional interplay is needed between the different sensory modalities and between the senses and the motor apparatus. Subsequently, the enactment of objects via this kind of sensorimotor contigencies gives rise to the emergence of concepts, for which there is evidence in higher cortical areas, like the inferotemporal cortex [1]. Due to Hebbian learning, objects with which we used to interact should be present in a sensory crossmodal memory. As Beets et al. (2010) pointed out, directed action coordinates available sensory information into action serving percepts [2]. While their work pointed to a direct action-perception interdependence, this work investigates how multimodal conceptual information stabilizes rivalling visual percepts. Of significance in this human psychophysical study is that real-world objects will be used as visual and haptic stimuli which are common to everyday interactive experience. This contrasts the more abstract and schematic nature of stimuli of some previous investigations where bottom-up processing of multimodal stimulation was enforced instead of top-down object semantics [3, 4].
What happens with two competing percepts (e. g. tennis ball vs. cellphone) during binocular rivalry when one of those real-world objects has to be enacted with hands? This question will be answered in two experimental approaches. During both experiments the perceptual switches will be reported verbally and physiologically by eye-tracking. 
In the first session, the haptic object will be given to the subject prior to the binocular stimulation. Here it is hypothesized that touching and recognizing an object introduces priming and hence a strong expectation bias in the visual domain due to previous somatosensory semantic activation. This will lead to a very quick, clear displacement of the rivalry towards the corresponding visual object. The rivalling visual object will be neglected most of the time. 
In the second session, the haptic object will be reached after a subject receives the binocular input. Here it is expected that additional haptic information resolves the sensory competition in favor of the touched object, because the concept gets activated in the visual domain. 
Einhäuser et al. (2008) showed that pupil diameter can serve as an objective measure for perceptual switches, whereby each new percept selection is accompanied by a pupil dilation [4]. The experimental approach will be conducted with a mirror stereoscope which will directly project two object images from two monitor displays. An eye tracker (EyeLink 1000) will be utilized to measure the pupil dilation dynamics and the eye movements respectively. To describe the temporal development of the percept selections, the independent variables are pupil dilation, perceptual switch frequency and the duration of the percept stability. In both sessions, it is expected that the percept switching frequency will be lowered leading to longer intervals of percept stabilization.
In case the hypotheses are verified, the work would suggest that the multimodal object recognition leads to disregarding of available additional perceptual information which conflicts the already integrated visuo-haptic evidence. That would mean that concept activation can influence the processing of available perceptual information in a top-down fashion. Since the binocular percept suppression is an active process [1], this implies that in order to create perceptual reality, the brain-body-system operates with inductive inference based on relevant and sufficient, instead of fully available sensory evidence.

