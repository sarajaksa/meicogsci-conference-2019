... title: 'Fictive' sounds in language: processing of abstract sentences encoding fictive sounds evoke sound representations



Abstract

Is there a qualitative difference between the understanding of concrete (Trains should blow their whistles at crossings) and abstract (The professor blew the whistle on the students for plagiarising) sentences that describe sounds? Previous reports have, for example, demonstrated that the comprehension of sentences describing auditory motion in a specific direction is affected by simultaneously viewing a stimulus that depicts motion in the same or opposite direction[3]. The present study reports two experiments that extend our understanding of the relationship between specific sounds (e.g., 'bark') and sentences.
The results show that visual sentence processing is not only affected by non-specific auditory stimuli (auditorily invoked white noises) as demonstrated by Kaschak and colleagues (2006)[3], such as directions but also by the simultaneous processing of specific sounds (e.g., musical instruments, animal sounds, environmental sounds, etc.). It is also demonstrated that sentences describing sounds automatically activate sound representations.
In Exeriment 1, 180 Hungarian participants were assigned to one of four experimental conditions at random: (1) congruent sounds, (2) incongruent sounds, (3) unrelated sounds, (4) no sound. The groups were defined by the kinds of sounds they heard while reading the critical sentences. For example, a sentence, such as 'The press rang alarm bells' was presented to the first group of participants together with the congruent sound ('ring'), to the second group with an incongruent sound ('drums'), and to the third group with an unrelated sound ('laughter').
The data show that sentences describing specific sounds are processed faster in the congruent condition compared to the incongruent and the no-sound condition. This effect was found also for the set of abstract sentences, a major finding of the experiment, which indicates that specific sounds also affect the processing of metaphorical sentences that do not refer to real sound events. Sentences in the unrelated sound condition were processed faster than those in the incongruent condition.
Experiment 2 investigated whether the processing of sentences encoding sounds automatically evoke sound representations. 92 Hungarian students participated in the experiment. Subjects were presented with sentences (rapid serial visual presentation paradigm - RSVP), and their task was to decide at the end of these whether the sounds they hear could have been produced by the event described by the sentence. The sounds were presented in synchrony with the the last word (the critical verb).
Three experimental conditions were contructed according to the critical sound categories: congruent, incongruent, and unrelated sounds. Congruent sounds are those that matched the meaning of the verb (e.g., a 'barking' sound after the sentence 'the dog was barking'). Incongruent sounds were taken from the same semantic category as the verb (e.g., the sound of a cat meowing after the sentence 'the dog was barking'). Mean verification time is the mean RT to sound stimuli after the concrete and the abstract sentences. Participants were expected to make a negative verification on sounds that were presented after the abstract test sentences, for these sound events are fictive, ie. they cannot incorporate the sound representation described by the metaphorical sentence.
The results show that unrelated sounds were reacted to significantly faster than congruent and incongruent sounds in both sub-samples (concrete and abstract). It is, therefore, argued that metaphorical sentences also activate sound representations. There was, however, no significant difference between the verification of congruent and incongruent sounds after the abstract sentences. This can be explained by the fact that - as opposed to concrete sentences - in the case of abstract sentences congruent sounds have to be responded to in the negative, which causes a delay in verification (inhibition).
Taken together, these findings provide evidence for an intimate two-way connection between specific sounds and metaphorical language describing non-referring sound events. It is suggested that sound representations incorporate the mental model recreated by linguistic representations. It is argued that the crucial role of sound simulation is elaboration. The results are discussed in the framework of Simulation Semantics[2] and the Theory of Language and Situated Simulation (LASS) [1].
Future research might fruitfully follow these directions: (1) The specificity of mental simulations is a very interesting question: do different kinds of concrete ringing sounds recruit different samples of auditory imagery (according to the sounds described implicitly in the sentences)? (2) it has been shown in Experiment 2 that incongruent sounds are verified faster after abstract sentences than after concrete ones. It would be worth pursuing further as to what causes this effect; are the representations that are activated by abstract linguistic labels less intense than those activated by concrete verbs describing specific sounds?

Key words: linguistic processing, environmental sounds, fictive sounds, auditory imagery, mental simulation, concrete versus abstract language, sentence processing, metaphor


References:

[1]	Barsalou, L.W.; Santos, A..; Simmons, W.K.; Wilson, C.D. (2008) Language and simulation in conceptual processing, In M. De Vega, A. M. Glenberg, and A. C. Graesser, A. (eds.). Symbols, embodiment, and meaning (245-283). Oxford: Oxford University Press.
[2]	Bergen, B.K. (2007) Experimental methods for simulation semantics, In Monica Gonzalez-
Marquez, Irene Mittelberg, Seana Coulson, and Michael J. Spivey (eds.) Methods in Cognitive Linguistics, Amsterdam: John Benjamins. [pp. 277-301]
[3]	Kaschak, M.P.; Zwaan, R.A.; Aveyard, M.; Yaxley, R.H. (2006) Perception of auditory motion affects sentence processing. Cognitive Science 30, 733-744.

