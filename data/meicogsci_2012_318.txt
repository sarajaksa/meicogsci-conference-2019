... title: Testing the hierarchical neural network DBN in invariant object recognition



Abstract

Neural networks (artificial and non-artificial) are important part of recent cognitive science and are related to connectionist theory. They are very important part of computer based artificial intelligence. Neural network is an universal mathematical approach in study and modeling of learning process, adaptation process and artificial cognitive systems. The whole concept of interconnected simple units is based on the metaphor of human brain. They are biologically motivated mechanisms of knowledge acvisition and learning (applicable on different levels of abstraction). Many connectionists think that brain executes computations and that neural computing explain human cognition. Mainly we suppose that we can use neural networks to explain mental processes. Connectionism in artificial intelligence and cognitive science are considered as processes of parallel information processing. Artificial neural networks have important role in cognitive science, linguistic, neuroscience[3] and in controlling of different processes. In these wide spectrum of possible applications neural networks are not used only for modeling learning and adaptation. They are also used for solving a wide spectrum of different tasks and problems like object classification [2], speech recognition, financial forecasting and navigation. But one of the main purpose of studying neural networks is because their relation to human brain. In cognitive science and neuroscience the neural networks are part of basic theoretical methods which model the activity of our brain. In these two scientific disciplines are created basic connectionistic principles and is shown plausibility of neural networks for modeling different kinds of activities and aspects of human brain. One of the main purpose of studying artificial neural networks is finding the relation between implemented mechanisms (in interaction between neurons) and cognitive phenomena [3]. Connectionism represents important knowledge base which is able to interpret and explain different cognitive activities of human brain. This connectionist representation of human brain is plausible with our knowledge about brain structure and it is supported by information about brain physiology. 

The purpose of this work is to test the ability of Deep belief network [1] in object classification problems. This model is a deep network with two phase training. The first one is unsupervised pre-training based on stack of Restricted boltzman machines. The second one is fine-tuning which uses back-propagation of error derivates. The motivation for using DBN was better performance in object classification task than classical feed-forward neural network. For high structured input data the back-propagation works better if the weights are initialized by DBN [1]. In this work are used two main image datasets for experiments. The first dataset is composed of pictures with 11 leaves classes. This dataset includes rotational, color, size and noise variability. The second dataset is composed of normal and abnormal faces. The goal was to train network to classify given images and to find the relationship among different network topologies, dataset parameters and final testing error. Based on my experiments I found out that unsupervised pre-training, which is used for weight initialization helps to achieve better classification performance than random weight initialization. The significance of this help depends on type of dataset. In faces dataset this help is bigger (6.8%) than in leaves dataset (1.1%). My experiments also confirm that a higher number of neurons and hidden layers increased classification performance.

Overall the network shows quite good image classification skills and there is potential for real usage of such classification method in practice (e. g. portable cell phone application). However there are also many another methods like recently presented Multi-column Deep Neural Networks [2]. Especially this recent network is very encouraging. Based on the fresh results on image classification task like CIFAR-10 or MNIST Multi-column Deep Neural Networks achieved the best performance. This field of research is very interesting for the application in robotics industries and there is also huge potential for cognitive science, because these methods are inspired by biology and functionality of neural system.

