... title: Robotic Superior Temporal Sulcus



Abstract

The topic of Superior temporal sulcus (STS) in mirror neuron system and motoric resonance is still discussed. STS is located in temporal lobe and encodes biological movements, but it responds only to visual stimuli incoming from lower levels of visual cortex. Based on empirical evidence, it is known, it plays crucial role in mirror neuron circuit and action recognition.
	According to research of D. I. Perrett, et al. [2] it was shown that it doesn't respond to objects or actions independently of viewpoint. In the experiment monkeys saw a face at four viewpoints. Activations of STS contains populations of neurons which were active for face seen from different viewpoints. They discovered existence of four main populations specialized on four cardinal directions (0, 90, 180, 270 deg.). For any viewpoint was dominantly active population for which was the viewpoint the most similar (eg. when monkey saw a face from 80° viewpoint, the 90° population was activated the most).  Similar property was later measured by V. Caggiano, et al. [3], but they were measuring activations of macaque mirror neurons in F5 area. Their monkeys were observing and performing grasping and reaching a food. Caggianos tema discovered similar organization of mirror neurons activations as was in the STS. There were also four main populations for cardinal directions and a small fraction of STS neurons was view-indipendent, they were active for all viewpoints.
	We have implemented simple model of STS with mentioned property of activation at different viewpoints. The key element of our model is recurrent self-oragnizing map. This neural network is based on Kohonens model extended with internal memory. Basically can be described as matrix of artificial neurons which is using hebbian (unsupervised) learning. We focused on two newer models: Merge SOM and Merge neural gas (MNG) proposed by M. Strickert and B. Hammer [1]. These two models are computational efficient and less memory consuming than older RecSOM or SOM-SD. MSOM doesn't copy whole hidden layer to context but uses context descriptor which is linear combination of current input and past contexts. MNG behaves in similar way but has no topology so neurons are acting as gas molecules. We have chosen a few measures to compare their capabilities (quantization error, information entropy).
	Our main goal was to simulate a behavior of STS when there is presented action seen from more viewpoints. The network obtained on the input preprocessed data containing sequences of  three types of motion. These were grasps generated by ICub robot simulator. In the first step, data were preprocessed: rotated and projected (exactly as it is done on eye retina) from 3D to 2D. So we have gained training set of three actions seen at four different viewpoints. In the next step the network was trained on this set and organized itself to cover all inputs. We are expecting creation of neuron clusters responding to each grasp seen at one of the four viewpoints.
	In future we are planning to extend this model and connect it to grater architecture. It should be the input module for computational model of simple mirror neuron system. It will be used in ICub robots (in simulator) and we believe the model could perform their action recognition and action mapping from our robotic STS to robotic F5.


[1] M. Strickert, B. Hammer, Merge SOM for temporal data, 2004
[2] D. I. Perrett, M. W. Oram, M. H. Harries, R. Bevan, J. K. Hietanen, P. J. Benson, and S. Thomas, Viewer-centred and object-centred coding of heads in the macaque temporal cortex, 1991 
[3] V. Caggiano,  et al., View-based encoding of actions in mirror neurons of area f5 in macaque premotor cortex,  2011

