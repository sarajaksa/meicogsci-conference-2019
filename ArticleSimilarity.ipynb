{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the script, that I used to filter the similar articles out. I was after the articles, that were written by the same group, but each author submitted one. This was allowed in the previous years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libaries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from constants import folder_meicogsci\n",
    "import pandas\n",
    "import string\n",
    "import scipy\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the helping functions and lists\n",
    "all_files = os.listdir(folder_meicogsci)\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "lem = nltk.stem.WordNetLemmatizer()\n",
    "stem = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of files\n",
    "number_of_files = len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesing the texts\n",
    "all_texts_and_ids = dict()\n",
    "for filename in all_files:\n",
    "    text_name = filename.split(\"_\")[-1].replace(\".txt\", \"\")\n",
    "    with open(os.path.join(folder_meicogsci, filename)) as f:\n",
    "        data_file = f.readlines()\n",
    "    # the the text is being put in the format, that makes it more informative to compare\n",
    "    data_file = \" \".join(data_file)\n",
    "    data_file = data_file.replace(\"... title:\", \"\")\n",
    "    data_file = data_file.lower()\n",
    "    data_file = data_file.replace(\"-\", \" \").replace(\"/\", \" \").replace(\"â€“\", \" \") \n",
    "    # here, the test is being split into words and compared based on that\n",
    "    data_words = nltk.tokenize.word_tokenize(data_file)\n",
    "    data_words = [w.strip() for w in data_words if w.strip()]\n",
    "    all_texts_and_ids[text_name] = data_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helping function\n",
    "def dummy(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing for creating a model\n",
    "all_texts = [text for text in all_texts_and_ids.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=dummy, preprocessor=dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_fit = vectorizer.fit_transform(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "tfidf_vectoring = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_response = tfidf_vectoring.fit_transform(vectorizer_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting TF-IDF into pandas\n",
    "test = pandas.DataFrame(tfidf_response.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = [current_id for current_id in all_texts_and_ids.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helping function\n",
    "def get_file_year(f1):\n",
    "    f1 = int(f1)\n",
    "    return [int(filename.split(\"_\")[1]) for filename in all_files if int(filename.split(\"_\")[2].split(\".\")[0]) == f1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caluclate the distance between articles\n",
    "all_distances = []\n",
    "for i in range(number_of_files):\n",
    "    for j in range(number_of_files):\n",
    "        if i > j:\n",
    "            d = scipy.spatial.distance.cosine(test.iloc[[i]], test.iloc[[j]])\n",
    "            all_distances.append([d, all_ids[i], all_ids[j], get_file_year(all_ids[i]), get_file_year(all_ids[j])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = pandas.DataFrame(all_distances, columns=[\"Cosine\", \"ID1\", \"ID2\", \"year1\", \"year2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The articles here are the ones that already survived the filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>year1</th>\n",
       "      <th>year2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209273</th>\n",
       "      <td>0.047670</td>\n",
       "      <td>360</td>\n",
       "      <td>407</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274175</th>\n",
       "      <td>0.091252</td>\n",
       "      <td>378</td>\n",
       "      <td>225</td>\n",
       "      <td>2012</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29993</th>\n",
       "      <td>0.101792</td>\n",
       "      <td>773</td>\n",
       "      <td>629</td>\n",
       "      <td>2015</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238843</th>\n",
       "      <td>0.149487</td>\n",
       "      <td>1037</td>\n",
       "      <td>1166</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83502</th>\n",
       "      <td>0.167938</td>\n",
       "      <td>256</td>\n",
       "      <td>294</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55725</th>\n",
       "      <td>0.170033</td>\n",
       "      <td>565</td>\n",
       "      <td>700</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73750</th>\n",
       "      <td>0.175360</td>\n",
       "      <td>892</td>\n",
       "      <td>631</td>\n",
       "      <td>2016</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201008</th>\n",
       "      <td>0.231220</td>\n",
       "      <td>219</td>\n",
       "      <td>361</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112224</th>\n",
       "      <td>0.238934</td>\n",
       "      <td>411</td>\n",
       "      <td>424</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>0.254491</td>\n",
       "      <td>722</td>\n",
       "      <td>801</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121185</th>\n",
       "      <td>0.265729</td>\n",
       "      <td>1066</td>\n",
       "      <td>1185</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173897</th>\n",
       "      <td>0.274301</td>\n",
       "      <td>324</td>\n",
       "      <td>322</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254708</th>\n",
       "      <td>0.280576</td>\n",
       "      <td>1062</td>\n",
       "      <td>913</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237808</th>\n",
       "      <td>0.312112</td>\n",
       "      <td>358</td>\n",
       "      <td>629</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201262</th>\n",
       "      <td>0.316172</td>\n",
       "      <td>219</td>\n",
       "      <td>269</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181446</th>\n",
       "      <td>0.321120</td>\n",
       "      <td>698</td>\n",
       "      <td>813</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58434</th>\n",
       "      <td>0.330779</td>\n",
       "      <td>314</td>\n",
       "      <td>424</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165092</th>\n",
       "      <td>0.346872</td>\n",
       "      <td>430</td>\n",
       "      <td>279</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79093</th>\n",
       "      <td>0.349111</td>\n",
       "      <td>427</td>\n",
       "      <td>492</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112443</th>\n",
       "      <td>0.349122</td>\n",
       "      <td>411</td>\n",
       "      <td>314</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cosine   ID1   ID2  year1  year2\n",
       "209273  0.047670   360   407   2012   2013\n",
       "274175  0.091252   378   225   2012   2011\n",
       "29993   0.101792   773   629   2015   2014\n",
       "238843  0.149487  1037  1166   2017   2018\n",
       "83502   0.167938   256   294   2011   2012\n",
       "55725   0.170033   565   700   2014   2015\n",
       "73750   0.175360   892   631   2016   2014\n",
       "201008  0.231220   219   361   2011   2012\n",
       "112224  0.238934   411   424   2013   2013\n",
       "3909    0.254491   722   801   2015   2016\n",
       "121185  0.265729  1066  1185   2017   2018\n",
       "173897  0.274301   324   322   2012   2012\n",
       "254708  0.280576  1062   913   2017   2016\n",
       "237808  0.312112   358   629   2012   2014\n",
       "201262  0.316172   219   269   2011   2011\n",
       "181446  0.321120   698   813   2015   2016\n",
       "58434   0.330779   314   424   2012   2013\n",
       "165092  0.346872   430   279   2013   2012\n",
       "79093   0.349111   427   492   2013   2013\n",
       "112443  0.349122   411   314   2013   2012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by differences in articles\n",
    "all_distances.sort_values(by=\"Cosine\", ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
